{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d158a06",
   "metadata": {},
   "source": [
    "<div style=\"padding:20px 30px 30px; \n",
    "            color:#004346;\n",
    "            font-size:40px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "<p style=\"font-weight: bold; text-align: center;\"> Project:  English Score </p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01446ca2",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 40px 30px; \n",
    "            color:#004346;\n",
    "            font-size:110%;\n",
    "            display:fill;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:450;\"> \n",
    "    \n",
    "__Постановка проблемы:__ Просмотр фильмов на оригинальном языке - это популярный и действенный метод прокачаться при изучении иностранных языков. Важно выбрать фильм, который подходит студенту по уровню сложности, т.е. студент понимал 50-70 % диалогов. Чтобы выполнить это условие, преподаватель должен посмотреть фильм и решить, какому уровню он соответствует. Однако это требует больших временных затрат.\n",
    "    \n",
    "__Цель:__ Разработать ML решение для автоматического определения уровня сложности англоязычных фильмов, разработать для неё веб-интерфейс и создать микросервис. \n",
    "    \n",
    "__Описание данных:__\n",
    "\n",
    "- субтитры фильмов, сохраненные в директориях, названия которых, соответствуют уровню сложности по шкале CEFR([Common European Framework of Reference]\n",
    "    \n",
    "- субтитры фильмов и [фaйл xlsx], содержаший название фильмов и уровню сложности по шкале CEFR\n",
    "    \n",
    "- список слов, по уровлю сложности Oxford level.\n",
    "</div>        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3daa0fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T12:51:38.731656100Z",
     "start_time": "2023-07-28T12:51:18.018284800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysrt in c:\\users\\ratim\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: chardet in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from pysrt) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pysrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff48c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T12:50:56.183464Z",
     "start_time": "2023-07-28T12:50:39.047716400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\ratim\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from optuna) (1.11.1)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from optuna) (0.10.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554910e4",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\ratim\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "                                              0.0/12.8 MB ? eta -:--:--\n",
      "                                              0.0/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "                                              0.0/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "                                             0.1/12.8 MB 544.7 kB/s eta 0:00:24\n",
      "                                             0.1/12.8 MB 737.3 kB/s eta 0:00:18\n",
      "                                             0.2/12.8 MB 893.0 kB/s eta 0:00:15\n",
      "                                              0.2/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "                                              0.3/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "     -                                        0.4/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     -                                        0.4/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     -                                        0.4/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     -                                        0.6/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     --                                       0.7/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     --                                       0.9/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "     ---                                      1.0/12.8 MB 1.9 MB/s eta 0:00:07\n",
      "     ---                                      1.2/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "     ----                                     1.3/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     ----                                     1.5/12.8 MB 2.3 MB/s eta 0:00:05\n",
      "     -----                                    1.7/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ------                                   1.9/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ------                                   2.0/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ------                                   2.0/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ------                                   2.0/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ------                                   2.0/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ------                                   2.0/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ------                                   2.0/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ------                                   2.1/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "     -------                                  2.4/12.8 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------                                3.1/12.8 MB 3.0 MB/s eta 0:00:04\n",
      "     ----------                               3.4/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "     -----------                              3.5/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "     -----------                              3.7/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "     ------------                             3.9/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "     ------------                             4.1/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     -------------                            4.2/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     -------------                            4.2/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     -------------                            4.2/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     -------------                            4.2/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     -------------                            4.2/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     -------------                            4.4/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     ----------------                         5.2/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     ----------------                         5.4/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     -----------------                        5.6/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     -----------------                        5.8/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "     ------------------                       5.9/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "     -------------------                      6.1/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "     -------------------                      6.3/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "     --------------------                     6.5/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------------                     6.7/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     ---------------------                    6.8/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     ---------------------                    6.9/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     ----------------------                   7.1/12.8 MB 3.7 MB/s eta 0:00:02\n",
      "     -----------------------                  7.4/12.8 MB 3.8 MB/s eta 0:00:02\n",
      "     -----------------------                  7.6/12.8 MB 3.8 MB/s eta 0:00:02\n",
      "     ------------------------                 7.8/12.8 MB 3.8 MB/s eta 0:00:02\n",
      "     -------------------------                8.0/12.8 MB 3.9 MB/s eta 0:00:02\n",
      "     -------------------------                8.2/12.8 MB 3.9 MB/s eta 0:00:02\n",
      "     --------------------------               8.4/12.8 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------------              8.7/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------------              8.9/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ----------------------------             9.1/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     -----------------------------            9.5/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------           9.7/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------          10.0/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------------------------         10.3/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------         10.5/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "     ---------------------------------        10.7/12.8 MB 4.9 MB/s eta 0:00:01\n",
      "     ----------------------------------       10.9/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     -----------------------------------      11.3/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------     11.5/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------     11.8/12.8 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------    12.0/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------------------   12.2/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 5.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abce56f9",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ratim\\anaconda3\\lib\\site-packages (1.7.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5de6c0",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\ratim\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from lightgbm) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74496b9c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\ratim\\anaconda3\\lib\\site-packages (1.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2022.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\ratim\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbef770",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Используемые библиотеки\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "366769c9",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ratim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pysrt\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "import csv\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.tokenize import word_tokenize\n",
    "import joblib\n",
    "import re\n",
    "import random\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "# константы\n",
    "RANDOM_SEED = 3826\n",
    "EARLY_STOPPING_ROUND = 100\n",
    "CV = 3\n",
    "VERBOSE = 100\n",
    "\n",
    "HTML = r'<.*?>' # html тэги меняем на пробел\n",
    "TAG = r'{.*?}' # тэги меняем на пробел\n",
    "COMMENTS = r'[\\(\\[][A-Za-z ]+[\\)\\]]' # комменты в скобках меняем на пробел\n",
    "UPPER = r'[[A-Za-z ]+[\\:\\]]' # указания на того кто говорит (BOBBY:)\n",
    "LETTERS = r'[^a-zA-Z\\'.,!? ]' # все что не буквы меняем на пробел \n",
    "SPACES = r'([ ])\\1+' # повторяющиеся пробелы меняем на один пробел\n",
    "DOTS = r'[\\.]+' # многоточие меняем на точку\n",
    "SYMB = r\"[^\\w\\d'\\s]\" # знаки препинания кроме апострофа\n",
    "\n",
    "# настройки блокнота\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306c09b",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Загрузка и первичная обработка данных\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5d8dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T12:55:51.454047100Z",
     "start_time": "2023-07-28T12:55:51.378559400Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Все данные загруженны коректно'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # путь к папке с файлами субтитров\n",
    "    subtitles_folder = Path('project_eng_scr/English_scores/Subtitles_all/level')\n",
    "    subtitles_folder2 = 'project_eng_scr/English_scores/Subtitles_all/Subtitles'\n",
    "    excel_file = 'project_eng_scr/English_scores/movies_labels.xlsx'\n",
    "    # загрузка данных для рассчета статистической информации:\n",
    "    a1_list = next(csv.reader(open('project_eng_scr/English_scores/a1.csv', 'r')))\n",
    "    a2_list = next(csv.reader(open('project_eng_scr/English_scores/a2.csv', 'r')))\n",
    "    b1_list = next(csv.reader(open('project_eng_scr/English_scores/b1.csv', 'r')))\n",
    "    b2_list = next(csv.reader(open('project_eng_scr/English_scores/b2.csv', 'r')))\n",
    "    c1_list = next(csv.reader(open('project_eng_scr/English_scores/c1.csv', 'r')))\n",
    "    display('Все данные загруженны коректно')\n",
    "except:\n",
    "    display('Данные не доступны')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c27575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:01:08.043221800Z",
     "start_time": "2023-07-28T13:01:07.739796800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bored', 'later', 'other', 'colour', 'friday']\n",
      "['engineer', 'jump', 'later', 'death', 'shape']\n",
      "['divide', 'battery', 'killing', 'studio', 'chest']\n",
      "['holy', 'popularity', 'committee', 'nasty', 'rescue']\n",
      "['morality', 'superb', 'acquisition', 'arbitrary', 'earnings']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2/A2+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                             Movie   Level\n",
       "0   0         10_Cloverfield_lane(2016)      B1\n",
       "1   1  10_things_I_hate_about_you(1999)      B1\n",
       "2   2              A_knights_tale(2001)      B2\n",
       "3   3              A_star_is_born(2018)      B2\n",
       "4   4                     Aladdin(1992)  A2/A2+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#проверяем как загрузизись данные\n",
    "print(a1_list[:5])\n",
    "print(a2_list[:5])\n",
    "print(b1_list[:5])\n",
    "print(b2_list[:5])\n",
    "print(c1_list[:5])\n",
    "exel = pd.read_excel(excel_file)\n",
    "display(exel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "611b0fc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:01:10.151257500Z",
     "start_time": "2023-07-28T13:01:09.995771700Z"
    }
   },
   "outputs": [],
   "source": [
    "# функция для первичной обработки текста\n",
    "def clean_subs(txt):\n",
    "    txt = re.sub(HTML, ' ', subs.text) # html тэги меняем на пробел\n",
    "    txt = re.sub(COMMENTS, ' ', txt) # комменты в скобках меняем на пробел\n",
    "    txt = re.sub(UPPER, ' ', txt) # указания на того кто говорит (BOBBY:)\n",
    "    txt = re.sub(LETTERS, ' ', txt) # все что не буквы меняем на пробел\n",
    "    txt = re.sub(DOTS, r'.', txt) # многоточие меняем на точку\n",
    "    txt = re.sub(SPACES, r'\\1', txt) # повторяющиеся пробелы меняем на один пробел\n",
    "    txt = re.sub(SYMB, '', txt) # знаки препинания кроме апострофа на пустую строку\n",
    "    txt = re.sub('www', '', txt) # кое-где остаётся www, то же меняем на пустую строку\n",
    "    txt = txt.lstrip() # обрезка пробелов слева\n",
    "    txt = txt.encode('ascii', 'ignore').decode() # удаляем все что не ascii символы   \n",
    "    txt = txt.lower() # текст в нижний регистр\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5dd2d",
   "metadata": {},
   "source": [
    "### Получение первой части размеченных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f076b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:01:29.429482300Z",
     "start_time": "2023-07-28T13:01:10.023957800Z"
    }
   },
   "outputs": [],
   "source": [
    "# получение списока файлов субтитров в папке\n",
    "subtitles_files = subtitles_folder.rglob('*.srt')\n",
    "# cоздание пустого датафрейма для хранения данных\n",
    "df = pd.DataFrame(columns=['movie', 'subtitles', 'label'])\n",
    "# загрузка и первичня обработка субтитров\n",
    "data = []\n",
    "for file_path in subtitles_files:\n",
    "    subs = pysrt.open(str(file_path), encoding='latin-1')\n",
    "    if len(subs) == 0:\n",
    "        subs = pysrt.open(str(file_path), encoding='utf-16') #учитываем альтернативную кодировку\n",
    "    txt = ' '.join([sub.text for sub in subs])\n",
    "    subtitle_text = clean_subs(txt)\n",
    "    data.append({'movie': file_path.name[:-4], 'subtitles': subtitle_text, 'label': file_path.parent.name})\n",
    "    \n",
    "# объединяем все записи в датасете с помощью функции concat\n",
    "df = pd.concat([df, pd.DataFrame(data)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f081890f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:01:29.628591900Z",
     "start_time": "2023-07-28T13:01:29.420937700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Walking Dead-S01E01-Days Gone Bye.English</td>\n",
       "      <td>little girl i'm a policeman little girl don't ...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Walking Dead-S01E02-Guts.English</td>\n",
       "      <td>mom right here any luck how do we tell if they...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead-S01E03-Tell It To The Frogs.E...</td>\n",
       "      <td>that's right you heard me bitch you got a prob...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Walking Dead-S01E04-Vatos.English</td>\n",
       "      <td>what nothing it's not nothing it's always some...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Walking Dead-S01E05-Wildfire.English</td>\n",
       "      <td>walkie talkie squawks morgan i don't know if y...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               movie  \\\n",
       "0      The Walking Dead-S01E01-Days Gone Bye.English   \n",
       "1               The Walking Dead-S01E02-Guts.English   \n",
       "2  The Walking Dead-S01E03-Tell It To The Frogs.E...   \n",
       "3              The Walking Dead-S01E04-Vatos.English   \n",
       "4           The Walking Dead-S01E05-Wildfire.English   \n",
       "\n",
       "                                           subtitles label  \n",
       "0  little girl i'm a policeman little girl don't ...    A2  \n",
       "1  mom right here any luck how do we tell if they...    A2  \n",
       "2  that's right you heard me bitch you got a prob...    A2  \n",
       "3  what nothing it's not nothing it's always some...    A2  \n",
       "4  walkie talkie squawks morgan i don't know if y...    A2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9f3411a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:01:30.364475300Z",
     "start_time": "2023-07-28T13:01:29.627586500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8cc0741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:01:30.571714300Z",
     "start_time": "2023-07-28T13:01:30.375546400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A2', 'B1', 'B2', 'C1'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbb90de",
   "metadata": {},
   "source": [
    "### Получение второй части размеченных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78728437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:01:30.848435800Z",
     "start_time": "2023-07-28T13:01:30.615476500Z"
    }
   },
   "outputs": [],
   "source": [
    "# загрузка датафрейма из файла excel\n",
    "df2 = pd.read_excel(excel_file)\n",
    "# удаление столбца, не использующего в дальнейшем анализе: `id`\n",
    "df2 = df2.drop('id', axis=1)\n",
    "# переименование признаков для последующей конкатинации датасетов\n",
    "df2.rename(columns = {\n",
    "    'Movie':'movie',\n",
    "    'Level':'label'\n",
    "    }, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3458274c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# функция для добавления судтитров, по названию фильмов и первичной обработки\n",
    "def add_srt(x):\n",
    "    try:\n",
    "        file_path = subtitles_folder2+x+'.srt'\n",
    "        subs = pysrt.open(file_path, encoding='latin-1')\n",
    "        if len(subs) == 0:\n",
    "            subs = pysrt.open(str(file_path), encoding='utf-16') #учитываем альтернативную кодировку\n",
    "        txt = ' '.join([sub.text for sub in subs])\n",
    "        clean_text = clean_subs(txt)\n",
    "        return clean_text\n",
    "    except FileNotFoundError:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b1b67fb",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B1', 'B2', 'A2/A2+', 'C1', 'B1, B2', 'A2/A2+, B1', 'A2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e290825",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#приводим значения A2/A2+ к стандартному значению B1 \n",
    "list_b1= df2.query('label == \"A2/A2+, B1\"').index.to_list()\n",
    "for i in list_b1:\n",
    "    df2.loc[i,'label']='B1'\n",
    "\n",
    "list_a2= df2.query('label == \"A2/A2+\"').index.to_list()\n",
    "for r in list_a2:\n",
    "    df2.loc[r,'label']='B1'\n",
    "#приводим значения B1, B2 к стандартному значению B1\n",
    "list_b2= df2.query('label == \"B1, B2\"').index.to_list()\n",
    "for q in list_b2:\n",
    "    df2.loc[q,'label']='B1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c027766f",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B1', 'B2', 'C1', 'A2'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "549742ac",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df2['subtitles'] = df2['movie'].apply(add_srt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4a34524",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>label</th>\n",
       "      <th>subtitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              movie label  subtitles\n",
       "0         10_Cloverfield_lane(2016)    B1        NaN\n",
       "1  10_things_I_hate_about_you(1999)    B1        NaN\n",
       "2              A_knights_tale(2001)    B2        NaN\n",
       "3              A_star_is_born(2018)    B2        NaN\n",
       "4                     Aladdin(1992)    B1        NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33927b3e",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cc59636",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af6eda2c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Walking Dead-S01E01-Days Gone Bye.English</td>\n",
       "      <td>little girl i'm a policeman little girl don't ...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Walking Dead-S01E02-Guts.English</td>\n",
       "      <td>mom right here any luck how do we tell if they...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead-S01E03-Tell It To The Frogs.E...</td>\n",
       "      <td>that's right you heard me bitch you got a prob...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Walking Dead-S01E04-Vatos.English</td>\n",
       "      <td>what nothing it's not nothing it's always some...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Walking Dead-S01E05-Wildfire.English</td>\n",
       "      <td>walkie talkie squawks morgan i don't know if y...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               movie  \\\n",
       "0      The Walking Dead-S01E01-Days Gone Bye.English   \n",
       "1               The Walking Dead-S01E02-Guts.English   \n",
       "2  The Walking Dead-S01E03-Tell It To The Frogs.E...   \n",
       "3              The Walking Dead-S01E04-Vatos.English   \n",
       "4           The Walking Dead-S01E05-Wildfire.English   \n",
       "\n",
       "                                           subtitles label  \n",
       "0  little girl i'm a policeman little girl don't ...    A2  \n",
       "1  mom right here any luck how do we tell if they...    A2  \n",
       "2  that's right you heard me bitch you got a prob...    A2  \n",
       "3  what nothing it's not nothing it's always some...    A2  \n",
       "4  walkie talkie squawks morgan i don't know if y...    A2  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60bd9a00",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d7afd",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #9966FF solid\">\n",
    "\n",
    "#### вывод по главе 'Загрузка и первичная обработка данных':\n",
    "- Субтитры загружены и объединены в датасет\n",
    "- Проведена первичная обработка субтитров:\n",
    "    - html тэги заменены на пробел\n",
    "    - комментарии заменены на пробел\n",
    "    - все что не является буквами заменены на пробел\n",
    "    - повторяющиеся пробелы заменены на один пробел\n",
    "    - многоточия заменены на точку\n",
    "    - удалены все что не ascii символы\n",
    "    - удалены первый и последний субтитр (обычно это реклама)\n",
    "    - весь текст переведен в нижний регистр для дальнейшей работы с ним\n",
    "    \n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927406f0",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Предобработка и исследовательский анализ данных\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d001c75",
   "metadata": {},
   "source": [
    "\n",
    "- Названия фильмов не несут информацию о сложности диалогов в нем, поэтому данный признак можно удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79be6f04",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дубликаты: 1\n",
      "дубликаты: 0\n"
     ]
    }
   ],
   "source": [
    "# удаление признака `movie`\n",
    "df = df.drop('movie', axis=1)\n",
    "# удаление записей с пропусками\n",
    "df = df.dropna()\n",
    "# удаление дубликатов\n",
    "print('дубликаты:', df.duplicated().sum())\n",
    "df = df.drop_duplicates()\n",
    "print('дубликаты:', df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b80d398",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 162 entries, 0 to 162\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subtitles  162 non-null    object\n",
      " 1   label      162 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35546a22",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B2    106\n",
      "C1     33\n",
      "B1     17\n",
      "A2      6\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7f2ce",
   "metadata": {},
   "source": [
    "- Cуществует дисбаланс класов\n",
    "\n",
    "- Небходимо:\n",
    "используя таблицу [таблицу CEFR/IELS](https://i.postimg.cc/W4YQxZkJ/2023-06-08-15-23-32.png) преобразобать значения в числовой вариант и в последующем решать задачу регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4029c08",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "cefr_dict = {'A2': 3.25, #среднее значение крайних значений [3.0 : 3.5]\n",
    "             'B1': 4.5,  #среднее значение крайних значений [4.0 : 5.0]\n",
    "             'B2': 6.0, #среднее значение крайних значений [5.5 : 6.5]\n",
    "             'C1': 7.5,} #среднее значение крайних значений [7.0 : 8.0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ae9b82c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df['ielts_index'] = df['label'].apply(lambda x: cefr_dict[x]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b376acf4",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:0px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "### Рассчет коофициентов удобочитаемости Флеша-Кинкейда\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f54e21",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #FF0000 solid\">\n",
    "\n",
    "Тесты на удобочитаемость [Флеша-Кинкейда](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level) — это тесты на удобочитаемость , предназначенные для определения того, насколько труден для понимания отрывок на английском языке . Есть два теста: Flesch Reading-Ease и Flesch-Kincaid Grade Level. Хотя они используют одни и те же основные меры (длина слова и длина предложения), они имеют разные весовые коэффициенты.\n",
    "\n",
    "- Flesch Reading-Ease:\n",
    "$$\n",
    "FRE = 206.835 - (words/sentences)*1.015 - (syllables/words)*84.6\n",
    "$$\n",
    "\n",
    "- Flesch-Kincaid Grade Level:\n",
    "$$\n",
    "FKGL = (words/sentences)*0.39 + (syllables/words)*11.8 - 15.59\n",
    "$$\n",
    "где:\n",
    "- words - количество слов в тексте;\n",
    "- sentences - количество предложений в тексте;\n",
    "- syllables - количество слогов в тексте\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbd9aeac",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# функции для рассчета коофициентов удобочитаемости:\n",
    "def statistics(txt):\n",
    "    total_sentences = len(re.split(r\"[.!?]\", txt))\n",
    "    total_words = len(txt.split(' '))\n",
    "    total_syllables = sum(txt.count(g) for g in 'aeoiu') + txt.count('y')/2\n",
    "    return total_sentences, total_words, total_syllables\n",
    "    \n",
    "def flesch_reading_ease(txt):\n",
    "    sentences, words, syllables = statistics(txt)\n",
    "    fres = 206.835 - (words/sentences)*1.015 - (syllables/words)*84.6\n",
    "    return fres\n",
    "    \n",
    "def flesch_kincaid_grade_level(txt):\n",
    "    sentences, words, syllables = statistics(txt)\n",
    "    fkgl = (words/sentences)*0.39 + (syllables/words)*11.8 - 15.59\n",
    "    return fkgl  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9ab8c80",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df['fres'] = df['subtitles'].apply(flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6c7dfb2",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df['fkgl'] = df['subtitles'].apply(flesch_kincaid_grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c1d0b",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:0px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "### Токенизация и лематизация текста\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c06ff",
   "metadata": {},
   "source": [
    "- Перед токенизацией текса, необходимо удалить оставшиеся знаки пунктуации и стоп-слова - список слов, которые не влияют на сложность текста, но могут уменьшить точность модели, а также провести Лемматизация и стемминг текста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc55dee",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px 20px; border: 2px #FF0000 solid\">\n",
    " \n",
    "    \n",
    "-  Токенизация - это процесс разделения предложений на слова-компоненты.\n",
    "-  Лемматизация - это процесс приведения словоформы к лемме — её нормальной (словарной) форме.\n",
    "-  стемминг- это процесс нахождения основы слова для заданного исходного слова.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4120de2",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Load the English library from SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create list of stopwords from spaCy\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fa22265",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# создаем фукцию токенаизер\n",
    "def spacy_tokenizer(sentence):\n",
    "    # создаем токен\n",
    "    tokens = nlp(sentence)\n",
    "    \n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"PROPN\" else word.lower_ for word in tokens]\n",
    "    \n",
    "    tokens = [word for word in tokens if word not in stopwords and word not in punctuations]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b2f84bc",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer,max_features=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de529c2",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:0px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "    \n",
    "### Рассчет долей слов относительно индекса CEFR\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3794345",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# cоздание пустого датафрейма для хранения данных\n",
    "df_info = pd.DataFrame(columns=['a1', 'a2', 'b1', 'b2', 'c1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9c827a1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "data_info = []\n",
    "# функция рассчета доли слов по уровням сложности\n",
    "def oxford_cefr(x):\n",
    "    a1 = sum(1 for i in x if i in a1_list)\n",
    "    a2 = sum(1 for i in x if i in a2_list)\n",
    "    b1 = sum(1 for i in x if i in b1_list)\n",
    "    b2 = sum(1 for i in x if i in b2_list)\n",
    "    c1 = sum(1 for i in x if i in c1_list)\n",
    "    count_word = a1+a2+b1+b2+c1\n",
    "    a1 = a1/count_word\n",
    "    a2 = a2/count_word\n",
    "    b1 = b1/count_word\n",
    "    b2 = b2/count_word\n",
    "    c1 = c1/count_word\n",
    "    data_info.append({'a1':a1, 'a2':a2, 'b1':b1, 'b2': b2, 'c1':c1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc6f566d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9min 50s\n",
      "Wall time: 9min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "158    None\n",
       "159    None\n",
       "160    None\n",
       "161    None\n",
       "162    None\n",
       "Name: subtitles, Length: 162, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df['subtitles'].apply(oxford_cefr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc7c4556",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# объединяем все записи в датасете с помощью функции concat\n",
    "df_info = pd.concat([df_info, pd.DataFrame(data_info)], ignore_index=True)\n",
    "df = pd.concat([df, df_info], axis=1).copy()\n",
    "# удаление записей с пропусками\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f968946b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtitles</th>\n",
       "      <th>label</th>\n",
       "      <th>ielts_index</th>\n",
       "      <th>fres</th>\n",
       "      <th>fkgl</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little girl i'm a policeman little girl don't ...</td>\n",
       "      <td>A2</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-3069.338469</td>\n",
       "      <td>1210.751560</td>\n",
       "      <td>0.599267</td>\n",
       "      <td>0.034799</td>\n",
       "      <td>0.331136</td>\n",
       "      <td>0.034799</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mom right here any luck how do we tell if they...</td>\n",
       "      <td>A2</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-3036.904170</td>\n",
       "      <td>1198.774790</td>\n",
       "      <td>0.591381</td>\n",
       "      <td>0.040785</td>\n",
       "      <td>0.327049</td>\n",
       "      <td>0.040785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that's right you heard me bitch you got a prob...</td>\n",
       "      <td>A2</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-3952.166828</td>\n",
       "      <td>1551.262784</td>\n",
       "      <td>0.608133</td>\n",
       "      <td>0.034036</td>\n",
       "      <td>0.323795</td>\n",
       "      <td>0.034036</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what nothing it's not nothing it's always some...</td>\n",
       "      <td>A2</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-3663.925591</td>\n",
       "      <td>1440.008546</td>\n",
       "      <td>0.600251</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>0.335213</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>walkie talkie squawks morgan i don't know if y...</td>\n",
       "      <td>A2</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-2952.000335</td>\n",
       "      <td>1166.312895</td>\n",
       "      <td>0.608340</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.315711</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           subtitles label  ielts_index  \\\n",
       "0  little girl i'm a policeman little girl don't ...    A2         3.25   \n",
       "1  mom right here any luck how do we tell if they...    A2         3.25   \n",
       "2  that's right you heard me bitch you got a prob...    A2         3.25   \n",
       "3  what nothing it's not nothing it's always some...    A2         3.25   \n",
       "4  walkie talkie squawks morgan i don't know if y...    A2         3.25   \n",
       "\n",
       "          fres         fkgl        a1        a2        b1        b2   c1  \n",
       "0 -3069.338469  1210.751560  0.599267  0.034799  0.331136  0.034799  0.0  \n",
       "1 -3036.904170  1198.774790  0.591381  0.040785  0.327049  0.040785  0.0  \n",
       "2 -3952.166828  1551.262784  0.608133  0.034036  0.323795  0.034036  0.0  \n",
       "3 -3663.925591  1440.008546  0.600251  0.032268  0.335213  0.032268  0.0  \n",
       "4 -2952.000335  1166.312895  0.608340  0.037975  0.315711  0.037975  0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3bf90",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #9966FF solid\">\n",
    "\n",
    "#### вывод по главе 'Предобработка и исследовательский анализ данных':\n",
    "    \n",
    "- Изучена общая информация.\n",
    "- Обработаны дубликаты и пропуски в данных.\n",
    "- Выявлен дисбаланс классов.\n",
    "- Удалены стоп-слова.\n",
    "- Проведена токенизация и лематизация текста.\n",
    "- Рассчитаны дополнительные признаки:\n",
    "    - Flesch Reading-Ease\n",
    "    - Flesch-Kincaid Grade Level\n",
    "    - Доли слов относительно индекса CEFR\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0d23d3",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Разработка модели ML\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e1cb0",
   "metadata": {},
   "source": [
    "- Для обучения моделей машинного обучения по прежнему не хватает записей, но так как субтитры в большенстве своем достаточно длинные, мы в праве разделить их по определенному количеству слов, тем самым увеличив количество записей. При этом рассчитанные ранее статистические данные следует оставить без изменений, тк они были рассчитаны на всем тексте и обладают большей точностью, по сравнению с теми, которые мы можем рассчитать на части данных.\n",
    "   - выберем количество: 100 слов \n",
    "- Некоторые записи могут содержать меньшее число слов, их следует исключить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac69a94b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# определение количества слов в субтитрах\n",
    "df['len'] = df['subtitles'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0279f91c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df = df[df['len']>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afca0b4e",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# cоздание пустого датафрейма для хранения данных\n",
    "df_div = pd.DataFrame(columns=['subtitles','a1', 'a2', 'b1', 'b2', 'c1', 'fres', 'fkgl','label', 'ielts_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f85a71c1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# функция для разделения субтитров\n",
    "len_div = 100 #количество слов в подвыборке, для увеличения наблюдений\n",
    "data = []\n",
    "def text_division(x):\n",
    "    for i in range(len(x['subtitles'])//len_div):\n",
    "        data.append({'subtitles': ' '.join(x['subtitles'][i*len_div:(i+1)*len_div+1]), \n",
    "                     'a1': x['a1'],\n",
    "                     'a2': x['a2'],\n",
    "                     'b1': x['b1'],\n",
    "                     'b2': x['b2'],\n",
    "                     'c1': x['c1'],\n",
    "                     'fres': x['fres'],\n",
    "                     'fkgl': x['fkgl'],\n",
    "                     'label': x['label'],\n",
    "                     'ielts_index': x['ielts_index']})                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a5aeb6e",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "157    None\n",
       "158    None\n",
       "159    None\n",
       "160    None\n",
       "161    None\n",
       "Length: 161, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.apply(text_division, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "261793c7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# объединяем все записи в датасете с помощью функции concat\n",
    "df = pd.concat([df_div, pd.DataFrame(data)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd825be",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "    \n",
    "### TF-IDF векторизация\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fbe4f",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px 20px; border: 2px #FF0000 solid\">\n",
    " \n",
    "- Векторизация текста - это процесс преобразования текстовых данных в числовые векторы, которые могут быть использованы в алгоритмах машинного обучения или анализа данных.\n",
    "    \n",
    "    \n",
    "- TF-IDF -  это метод который присваивает каждому слову в тексте числовое значение, основанное на его частоте встречаемости в документе (Term Frequency) и обратной частоте встречаемости в корпусе документов (Inverse Document Frequency).Результатом векторизации текста с использованием TF-IDF является числовое представление текста, где каждое слово представлено числовым значением, отражающим его важность в контексте данного текста.\n",
    "    \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a200f",
   "metadata": {},
   "source": [
    "- Для обучения модели, необходима векторизация текстовой информации.\n",
    "- Так же необходимо ограничить размерность матрицы, т.к. в случае сохранения всех параметров, потребуется много времени для реализации данного алгоритма обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1b10f43",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер тренировочной выборки: (34696, 8), (34696, 1)\n",
      "размер валидационной выборки:(9639, 8), (9639, 1)\n",
      "размер тестовой выборки:(3856, 8), (3856, 1)\n"
     ]
    }
   ],
   "source": [
    "# признаки для обучения\n",
    "X = ['subtitles', 'a1', 'a2', 'b1', 'b2', 'c1', 'fres', 'fkgl']\n",
    "# целевой признак\n",
    "y = ['ielts_index']\n",
    "\n",
    "# выборки для подбора гиперпараметров CatBoost\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(df[X], df[y], test_size=0.2,\n",
    "                                                                              random_state=RANDOM_SEED)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_train, target_train,\n",
    "                                                                            test_size=0.1, random_state=RANDOM_SEED)\n",
    "print(f'размер тренировочной выборки: {features_train.shape}, {target_train.shape}' )\n",
    "print(f'размер валидационной выборки:{features_valid.shape}, {target_valid.shape}')\n",
    "print(f'размер тестовой выборки:{features_test.shape}, {target_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aba733a2",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность обучающей матрицы TF-IDF: (34696, 24)\n",
      "Размерность тестовой матрицы TF-IDF: (3856, 24)\n",
      "CPU times: total: 20min 31s\n",
      "Wall time: 20min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_train_vectorized = tfidf_vector.fit_transform(features_train['subtitles'])\n",
    "features_test_vectorized = tfidf_vector.transform(features_test['subtitles'])\n",
    "# Вывод размерности матрицы TF-IDF\n",
    "print(\"Размерность обучающей матрицы TF-IDF:\", features_train_vectorized.shape)\n",
    "print(\"Размерность тестовой матрицы TF-IDF:\", features_test_vectorized.shape)\n",
    "\n",
    "# Преобразование векторизованного столбца 'subtitles' в массив NumPy\n",
    "features_train_vectorized = features_train_vectorized.toarray()\n",
    "features_test_vectorized = features_test_vectorized.toarray()\n",
    "\n",
    "# Объединение данных в один набор\n",
    "features_train_combined = np.hstack((features_train_vectorized, features_train.drop('subtitles', axis=1)))\n",
    "features_test_combined = np.hstack((features_test_vectorized, features_test.drop('subtitles', axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2737c0",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
    "\n",
    "#### промежуточный вывод:\n",
    "- Увеличен размер выборки за счет разделения субтитров на несколько записей.\n",
    "- Датафрейм разделен на обучающую и тестовую выборки.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c92d24",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "    \n",
    "# Обучение моделей\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b9ebc",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:0px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "    \n",
    "### RandomForestRegressor\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5e620b8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# гиперпараметры модели\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [5, 7],\n",
    "    'min_samples_split': [2, 3]\n",
    "}\n",
    "# параметры модели\n",
    "model_RF = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "# объект метрики MAE\n",
    "scorer = make_scorer(mean_absolute_error)\n",
    "# параметры RandomizedSearchCV\n",
    "random_search_RF = RandomizedSearchCV(estimator=model_RF,\n",
    "                                      param_distributions=param_grid,\n",
    "                                      n_iter=100,\n",
    "                                      cv=3,\n",
    "                                      verbose=True,\n",
    "                                      random_state=RANDOM_SEED,\n",
    "                                      scoring=scorer,\n",
    "                                      n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45132d5c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Оптимальные гиперпараметры:\n",
      "{'n_estimators': 150, 'min_samples_split': 2, 'max_depth': 5}\n",
      " mae: 0.41439941231419164\n",
      "CPU times: total: 1min 8s\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# обучение модели\n",
    "random_search_RF.fit(features_train_combined, target_train.values.ravel())\n",
    "# сохраним лучшую модель\n",
    "best_model_RF = random_search_RF.best_estimator_\n",
    "# сохраним лучшее значение метрики\n",
    "final_metrics_RF = random_search_RF.best_score_\n",
    "# вывод результатов\n",
    "print(f'Оптимальные гиперпараметры:\\n{random_search_RF.best_params_}\\n mae: {final_metrics_RF}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47479b3c",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
    "\n",
    "#### промежуточный вывод:\n",
    "- Оптимальные гитерпараметры для алгоритма RandomForest:\n",
    "    - 'n_estimators': 150\n",
    "    - 'min_samples_split': 2\n",
    "    - 'max_depth': 5\n",
    "---\n",
    "- Метрика качества MAE на обучающих данных при кроссвалидации составляет: 0.41\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c3f10",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:0px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\">\n",
    "    \n",
    "### CatBoost\n",
    "  \n",
    "<div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd136d3",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "<div style=\"padding: 10px 20px; border: 2px #FF0000 solid\">\n",
    "    \n",
    "- Градиентный бустинг (Gradient Boosting Machine - GBM) – это метод Машинного обучения (ML) для задач Регрессии (Regression) и Классификации (Classification), который создает прогнозирующую Модель (Model) в форме Ансамбля (Ensemble) слабых алгоритмов прогнозирования, обычно Деревьев решений (Decision Tree).\n",
    "- Ансамбль – это просто набор ML моделей, которые собираются вместе с помощью, например, среднего значения всех прогнозов, чтобы дать окончательный.\n",
    "- CatBoost - это градиентный бустинговый алгоритм, разработанный компанией Yandex. Он является мощным инструментом для задач классификации и регрессии, который обладает рядом преимуществ и особенностей.\n",
    "    \n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd568a5f",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# тестовые признаки \n",
    "text_features = ['subtitles']\n",
    "# pool\n",
    "train_pool = Pool(features_train,\n",
    "                  target_train,\n",
    "                  text_features=text_features)\n",
    "\n",
    "test_pool = Pool(features_test,\n",
    "                 text_features=text_features)\n",
    "# целевой признак тестовой выборки\n",
    "target_test_cb = target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a9dcc5",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "<div style=\"padding:1px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:0px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "                \n",
    "### optuna-подбор оптимальных гиперпараметров\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b0b433d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# гиперпараметры optuna\n",
    "def objective(trial):\n",
    "    param = {}\n",
    "    param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
    "    param['depth'] = trial.suggest_int('depth', 9, 15)\n",
    "    param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
    "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
    "    param['grow_policy'] = 'Depthwise'\n",
    "    param['iterations'] = 1000\n",
    "    param['use_best_model'] = True\n",
    "    param['eval_metric'] = 'MAE'\n",
    "    param['od_type'] = 'iter'\n",
    "    param['od_wait'] = 20\n",
    "    param['random_state'] = RANDOM_SEED\n",
    "    param['logging_level'] = 'Silent'\n",
    "    param['text_features'] = text_features\n",
    "    \n",
    "    regressor = CatBoostRegressor(**param)\n",
    "\n",
    "    regressor.fit(features_train.copy(), target_train.copy(),\n",
    "                  eval_set=[(features_test.copy(), target_test.copy())],\n",
    "                  early_stopping_rounds=EARLY_STOPPING_ROUND)\n",
    "    loss = mean_absolute_error(target_valid, regressor.predict(features_valid.copy()))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7063dd6c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-29 18:33:21,903] A new study created in memory with name: catboost-seed3826\n",
      "[I 2023-07-29 20:03:04,494] Trial 3 finished with value: 0.0041476218377971925 and parameters: {'learning_rate': 0.02, 'depth': 12, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 3 with value: 0.0041476218377971925.\n",
      "[I 2023-07-29 20:50:34,165] Trial 1 finished with value: 0.005751127439628427 and parameters: {'learning_rate': 0.02, 'depth': 14, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 3 with value: 0.0041476218377971925.\n",
      "[I 2023-07-29 21:05:49,800] Trial 2 finished with value: 0.005014450154523328 and parameters: {'learning_rate': 0.019000000000000003, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 32}. Best is trial 3 with value: 0.0041476218377971925.\n",
      "[I 2023-07-29 22:44:21,171] Trial 4 finished with value: 0.00510047017937372 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 15, 'l2_leaf_reg': 1.0, 'min_child_samples': 16}. Best is trial 3 with value: 0.0041476218377971925.\n",
      "[I 2023-07-29 22:47:23,563] Trial 7 finished with value: 0.006004296758622855 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 13, 'l2_leaf_reg': 3.5, 'min_child_samples': 4}. Best is trial 3 with value: 0.0041476218377971925.\n",
      "[I 2023-07-29 22:48:43,942] Trial 5 finished with value: 0.004554929164083166 and parameters: {'learning_rate': 0.01, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}. Best is trial 3 with value: 0.0041476218377971925.\n",
      "[I 2023-07-29 22:59:03,124] Trial 0 finished with value: 0.006179148718275586 and parameters: {'learning_rate': 0.015, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 8}. Best is trial 3 with value: 0.0041476218377971925.\n",
      "[I 2023-07-29 23:00:55,762] Trial 6 finished with value: 0.006171809836141344 and parameters: {'learning_rate': 0.017, 'depth': 12, 'l2_leaf_reg': 3.0, 'min_child_samples': 1}. Best is trial 3 with value: 0.0041476218377971925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7h 59min 15s\n",
      "Wall time: 4h 27min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study(study_name=f'catboost-seed{RANDOM_SEED}')\n",
    "study.optimize(objective, n_trials=1000, n_jobs=-1, timeout=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "affb5902",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " лучшая метрика: \n",
      "0.0041476218377971925\n",
      " оптимальные гиперпараметры: {'learning_rate': 0.02, 'depth': 12, 'l2_leaf_reg': 1.5, 'min_child_samples': 32}\n"
     ]
    }
   ],
   "source": [
    "print(f' лучшая метрика: \\n{study.best_value}\\n оптимальные гиперпараметры: {study.best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b22465",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
    "\n",
    "#### промежуточный вывод:\n",
    "- Оптимальные гитерпараметры для алгоритма CatBoost, при использовании алгоритма optuna:\n",
    "    - 'learning_rate': 0.02\n",
    "    - 'depth': 12\n",
    "    - 'l2_leaf_reg': 1.5\n",
    "    - 'min_child_samples': 32\n",
    "    \n",
    "- Метрика качества MAE на обучающих данных при кроссвалидации составляет: 0.004\n",
    "    ____________\n",
    "    \n",
    "- Для дальнейшего обучения выбираем алгоритм CatBoost, показывающий лучшую метрику качества. Однако, часть параметров не будет использоваться далее, что увеличит скорость обучения и предсказаний. В дальнейшем, при необходимости более точных данных, можно их можно будет использовать в модели.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4494ba48",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# гиперпараметры модели\n",
    "parameters = {'verbose': VERBOSE,\n",
    "              'text_features': ['subtitles'],\n",
    "              'eval_metric': 'MAE',\n",
    "              'iterations': 1000,\n",
    "              'learning_rate': 0.02,\n",
    "              'random_seed':RANDOM_SEED,\n",
    "              'early_stopping_rounds': 30\n",
    "             }\n",
    "# параметры модели\n",
    "regressor = CatBoostRegressor(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "798dba90",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5867878\ttotal: 33.3ms\tremaining: 33.3s\n",
      "100:\tlearn: 0.3589777\ttotal: 3.27s\tremaining: 29.2s\n",
      "200:\tlearn: 0.2528778\ttotal: 6.32s\tremaining: 25.1s\n",
      "300:\tlearn: 0.1883388\ttotal: 9.35s\tremaining: 21.7s\n",
      "400:\tlearn: 0.1423854\ttotal: 12.7s\tremaining: 18.9s\n",
      "500:\tlearn: 0.1094007\ttotal: 16s\tremaining: 16s\n",
      "600:\tlearn: 0.0832777\ttotal: 19.1s\tremaining: 12.7s\n",
      "700:\tlearn: 0.0647134\ttotal: 22.3s\tremaining: 9.51s\n",
      "800:\tlearn: 0.0497025\ttotal: 25.7s\tremaining: 6.38s\n",
      "900:\tlearn: 0.0380284\ttotal: 29.3s\tremaining: 3.22s\n",
      "999:\tlearn: 0.0303971\ttotal: 32.6s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x212057ab550>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# обучение модели\n",
    "regressor.fit(train_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285c384",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "<div style=\"padding:1px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:0px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "## Проверка модели на тестовой выборке\n",
    "    \n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08846380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя абсолютная ошибка (MAE): 0.030059597477530956\n"
     ]
    }
   ],
   "source": [
    "# предказание данных\n",
    "predict = regressor.predict(test_pool)\n",
    "mae = mean_absolute_error(target_test_cb, predict)\n",
    "# вывод результатов\n",
    "print(\"Средняя абсолютная ошибка (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50063ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение итоговой модели\n",
    "regressor.save_model('catboost_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6dd11",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#9966FF;\n",
    "            background-color: #FFFFCC;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Вывод\n",
    "    \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad9d831",
   "metadata": {},
   "source": [
    "- В ходе проведения исследования была выполнена предобработка данных, включающая очистку и лемматизацию текстовых признаков. Для векторизации текста был применен метод TF-IDF, который позволяет представить тексты в виде числовых признаков, учитывающих важность каждого термина в документе.\n",
    "\n",
    "- Для настройки гиперпараметров модели CatBoost был использован фреймворк Optuna. Optuna провел исследование пространства гиперпараметров, оценивая производительность модели с различными комбинациями параметров. Целевая метрика, в данном случае MAE, была определена для оптимизации. В результате подбора гиперпараметров были получены оптимальные значения, которые позволяют достичь наилучшей производительности модели CatBoost на данной задаче и составиляют 0.03 на тестовой выборке.\n",
    "\n",
    "- Полученная модель будет использоваться в разработке сервиса, предназначенного для определения уровня сложности английского языка в фильмах. Этот сервис будет доступен через платформу Streamlit, что позволит пользователям оценивать и анализировать сложность субтитров и основываться на предсказанных значениях индекса IELTS или CEFR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
